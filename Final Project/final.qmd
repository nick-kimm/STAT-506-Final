---
title: "506-Final"
author: "Nick Kim"
format: html
---

## What makes a Championship Roster?

```{r}
library(nflreadr)
library(nflverse)
library(dbplyr)
```
Contract data
```{r}
nflreadr::dictionary_contracts
contracts<-as.data.frame(nflreadr::load_contracts())
contracts
```
Roster data per season
```{r}
nflreadr::dictionary_rosters
cur_season<-as.data.frame(nflreadr::load_rosters())
unique(cur_season$status)
```
```{r}
cur_season[cur_season$status=="RES"|cur_season$status=="ACT",]|>
  merge(x=_,contracts[,c(10,16)],by="gsis_id")|>
  _[,c(1:4,8,37)]
```
```{r}
test<-contracts[contracts$gsis_id == "00-0023459" & !is.na(contracts$gsis_id), c(1,3,5:6,10)]
test
```

```{r}
library(dplyr)
target_yr = 2024
fil<-contracts[
  contracts$year_signed <= target_yr & 
    (contracts$years + contracts$year_signed - 1)>= target_yr,
]
fil[order(fil$gsis_id),]
```

```{r}
fil %>% 
  group_by(gsis_id) %>%
  filter(year_signed == max(year_signed))
```

```{r}
fil<-fil %>% 
  group_by(gsis_id) %>% 
  slice_tail(n=1)

#took last row as from looking at how OTC formats data in goes sequentially where last row is latest

fil
```
```{r}
test<-cur_season[cur_season$status=="RES"|cur_season$status=="ACT",]|>
  merge(x=_,fil[,c(10,16)],by="gsis_id")|>
  _[,c(1:4,8,37)]

test
```

Now need to implement a function to create this dataset for all seasons I want to test
```{r}
cappy <- function(year){
  season<-as.data.frame(nflreadr::load_rosters(year))
  
  fil<-contracts[
  contracts$year_signed <= year & 
    (contracts$years + contracts$year_signed - 1)>= year,
  ] %>% 
    group_by(gsis_id) %>% 
    filter(year_signed == max(year_signed)) %>% 
    slice_tail(n=1)
  

  
  cap_season<-season[season$status=="RES"|season$status=="ACT",] %>% 
    merge(fil[,c("apy_cap_pct","gsis_id")],by="gsis_id") %>% 
    select(gsis_id, season, team, position, full_name, apy_cap_pct)
  return(cap_season)
}
```

```{r}
all_seasons <- vector(mode = "list", length = 25)
i <- 1
for (yr in 2000:2024){
  all_seasons[[i]] <- cappy(yr)
  i = i + 1
}
```
```{r}
df <- do.call("rbind", all_seasons)
df$team <-replace(df$team,df$team=="SL", "LA") #renaming SL to LA due to relocation of the franchise to LA in last decade

```
```{r}
all_seasons[[18]][all_seasons[[18]]$full_name=="Matthew Stafford",]
```


Process to implement logistic regression

First need dataframe with all previous champions
```{r}
champs <- data.frame(
  season = c(2000:2023),
  champ = c("BAL","NE","TB","NE","NE","PIT","IND","NYG","PIT","NO","GB","NYG","BAL","SEA","NE",
            "DEN","NE","PHI","NE","KC","TB","LA","KC","KC")
)
```

adding binary var of champ to dataset
```{r}
df <- merge(df, champs, by = "season", all.x = TRUE)

df$is_champ <- ifelse(df$team==df$champ,1,0)

df
```

```{r}
unique(df$team)
length(unique(df$team))
```

Need to rename ARZ to ARI, SD to LAC, OAK to LV, HST to HOU, BLT to BAL, STL to LA, CLE to CLV

```{r}
team_rename <- c("ARZ" = "ARI", "SD" = "LAC", "OAK" = "LV", "HST" = "HOU", "BLT" = "BAL", "STL" = "LA", "CLE" = "CLV")

df$team <- ifelse(!is.na(match(df$team, names(team_rename))), team_rename[df$team], df$team)

unique(df$team)
length(unique(df$team))
```

Looking to see what year to run analysis on. There are 11 starting positions, and 53 total roster spots.
```{r}
for (yr in 2000:2024){
  print(yr)
  print(table(df[df$season==yr,"team"]))
}
```

```{r}
df_fil <- df[df$season>=2009,]

df_pos<-df_fil %>% group_by(season, team, position) %>% 
  summarise(cap_by_pos = sum(apy_cap_pct),.groups = "drop") %>% ungroup() %>% 
  group_by(season, team) %>% 
  mutate(total_cap = sum(cap_by_pos),
         prop_pos_cap = cap_by_pos/total_cap)

unique(df$position)
df_pos
```

```{r}
team_dat <- df_pos %>%
  group_by(season, team) %>%
  summarize(
    qb_cap_pct = sum(cap_by_pos[position == "QB"], na.rm = TRUE),
    rb_cap_pct = sum(cap_by_pos[position == "RB"], na.rm = TRUE),
    wr_cap_pct = sum(cap_by_pos[position == "WR"], na.rm = TRUE),
    te_cap_pct = sum(cap_by_pos[position == "TE"], na.rm = TRUE),
    ol_cap_pct = sum(cap_by_pos[(position == "OL"|position == "C"|position == "G"|position == "T")], na.rm = TRUE),
    lb_cap_pct = sum(cap_by_pos[(position == "LB"|position == "ILB"|position == "OLB"|position == "MLB")], na.rm = TRUE),
    dl_cap_pct = sum(cap_by_pos[(position == "DL"|position == "DE"|position == "DT"|position == "NT")],na.rm=TRUE),
    db_cap_pct = sum(cap_by_pos[position == "DB"], na.rm = TRUE),
    s_cap_pct = sum(cap_by_pos[(position == "FS"|position == "SS"|position == "S")]),
    spec_cap_pct = sum(cap_by_pos[(position == "K"|position =="P"|position == "KR"|position == "LS")]),
    
    total_cap_pct = sum(cap_by_pos, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  left_join(champs, by = "season") %>%
  mutate(is_champion = ifelse(team == champ, 1, 0))

```

```{r}
team_dat[team_dat$is_champion==1,]
```

Plotting distribution of is_champ for all variables
```{r}
library(ggplot2)
bf_24 <- team_dat[team_dat$season < 2024,]

variables <- c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", "lb_cap_pct", "db_cap_pct","te_cap_pct","ol_cap_pct","dl_cap_pct","s_cap_pct","spec_cap_pct","total_cap_pct")

for (v in variables){
  print(ggplot(bf_24,aes(x=.data[[v]],y=is_champion,color=is_champion))+geom_point())
}
```

Plotting all interactions
```{r}
library(ggplot2)

bf_24 <- team_dat[team_dat$season < 2024,]

variables <- c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", "lb_cap_pct", "db_cap_pct","te_cap_pct","ol_cap_pct","dl_cap_pct","s_cap_pct","spec_cap_pct","total_cap_pct")

for (i in variables){
  for (j in variables[variables != i]){
    print(ggplot(bf_24,aes(x=.data[[i]],y=.data[[j]], colour = as.factor(is_champion)))+
  geom_point())
  }
}
```


splitting into train and test
```{r}
pred_24 <- team_dat[team_dat$season==2024,]

dat_bf <- team_dat[team_dat$season < 2024,]

smp_size <- floor(0.75 * nrow(dat_bf))

set.seed(123)
train_ind <- sample(seq_len(nrow(dat_bf)), size = smp_size)

train <- dat_bf[train_ind,]
test <- dat_bf[-train_ind,]

y_train <- dat_bf[train_ind,15]
y_test <- dat_bf[-train_ind,15]

x_train <- dat_bf[train_ind,3:13]
x_test <- dat_bf[-train_ind,3:13]

model <- glm(is_champion ~ qb_cap_pct + rb_cap_pct + wr_cap_pct + te_cap_pct + ol_cap_pct + lb_cap_pct + db_cap_pct + dl_cap_pct + s_cap_pct + spec_cap_pct + total_cap_pct, 
             data = train, 
             family = "binomial")
summary(model)
```
```{r}
pred<-predict(model,newdata=test,type="response")
pred_champ<-ifelse(pred>0.5,1,0)
library(caret)
confusionMatrix(as.factor(pred_champ), as.factor(test$is_champion))
```
```{r}
pred<-predict(model,newdata=pred_24,type="response")
pred_24[order(pred, decreasing = TRUE),]
pred_24[pred>0.5,]
```
```{r}
library(car)

VIF <- vif(model)
as.data.frame(VIF)

cor_matrix<-cor(bf_24[,c("qb_cap_pct","rb_cap_pct","wr_cap_pct","te_cap_pct","ol_cap_pct","lb_cap_pct","db_cap_pct","dl_cap_pct","s_cap_pct","spec_cap_pct")])

table(bf_24$is_champion)
```
```{r}
model2 <- glm(is_champion ~ qb_cap_pct + rb_cap_pct + wr_cap_pct + te_cap_pct + ol_cap_pct + lb_cap_pct + db_cap_pct + dl_cap_pct, 
             data = train[3:15], 
             family = "binomial")
summary(model2)
```
```{r}
pred<-predict(model2,newdata=test,type="response")
pred_champ<-ifelse(pred>0.5,1,0)
library(caret)
confusionMatrix(as.factor(pred_champ), as.factor(test$is_champion))
```
```{r}
pred_log<-predict(model2,newdata=pred_24,type="response")
champ_log<-pred_24[order(pred_log, decreasing = TRUE),]
pred_24[which(pred>0.5),]
```


See that class imbalance might have an effect on model. Will account for this by adding class weights
```{r}
class_weights <- ifelse(train$is_champion==1,
                        1/sum(train$is_champion==1,na.rm=TRUE),
                        1/sum(train$is_champion==0,na.rm=TRUE))

model_w <- glm(is_champion ~ qb_cap_pct + rb_cap_pct + wr_cap_pct + te_cap_pct + ol_cap_pct + lb_cap_pct + db_cap_pct + dl_cap_pct + s_cap_pct + spec_cap_pct, 
             data = train, 
             family = "binomial",
             weights = class_weights)

summary(model_w)
```

```{r}
threshold <- 0.9
pred<-predict(model_w,newdata=test,type="response")
pred_champ<-ifelse(pred>threshold,1,0)
confusionMatrix(as.factor(pred_champ), as.factor(test$is_champion))
```
```{r}
pred_w<-predict(model_w,newdata=pred_24,type="response")
champ_w<-pred_24[order(pred_w, decreasing = TRUE),]
pred_24[which(pred_w>threshold),]
```

```{r}
library(pROC)
roc_curve <- roc(test$is_champion, pred_champ)
plot(roc_curve)
auc(roc_curve)
```
Trying different models

Ridge
```{r}
library(glmnet)

train_clean <- na.omit(train[, c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", 
                                 "te_cap_pct", "ol_cap_pct", "lb_cap_pct", 
                                 "db_cap_pct", "dl_cap_pct", "s_cap_pct", 
                                 "spec_cap_pct", "is_champion")])

x<-as.matrix(train_clean[,1:10])

y<-train_clean$is_champion

class_weights2 <- ifelse(train_clean$is_champion==1,
                        1/sum(train_clean$is_champion==1,na.rm=TRUE),
                        1/sum(train_clean$is_champion==0,na.rm=TRUE))

ridge.train = cv.glmnet(x, y, family = "binomial",alpha = 0,weights = class_weights2)
coefficient.ridge = coef(ridge.train, s = "lambda.min")
coefficient.ridge
predict.lasso <- predict(ridge.train, newx = as.matrix(test[,c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", 
                                 "te_cap_pct", "ol_cap_pct", "lb_cap_pct", 
                                 "db_cap_pct", "dl_cap_pct", "s_cap_pct", 
                                 "spec_cap_pct")]), s = "lambda.min")
pred_champ<-ifelse(predict.lasso>0.6,1,0)
confusionMatrix(as.factor(pred_champ), as.factor(test$is_champion))
```
```{r}
pred_24_rid <- as.matrix(pred_24[, c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", "lb_cap_pct", "db_cap_pct","te_cap_pct","ol_cap_pct","dl_cap_pct","s_cap_pct","spec_cap_pct")])
pred<-predict(ridge.train,newx=pred_24_rid, s = "lambda.min")
order(pred, decreasing = TRUE)
pred_24[order(pred, decreasing = TRUE),]
```

LASSO
```{r}
library(glmnet)

train_clean <- na.omit(train[, c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", 
                                 "te_cap_pct", "ol_cap_pct", "lb_cap_pct", 
                                 "db_cap_pct", "dl_cap_pct", "s_cap_pct", 
                                 "spec_cap_pct", "is_champion")])

x<-as.matrix(train_clean[,1:10])

y<-train_clean$is_champion

class_weights2 <- ifelse(train_clean$is_champion==1,
                        1/sum(train_clean$is_champion==1,na.rm=TRUE),
                        1/sum(train_clean$is_champion==0,na.rm=TRUE))

ridge.train = cv.glmnet(x, y, family = "binomial",alpha = 1,weights = class_weights2)
coefficient.ridge = coef(ridge.train, s = "lambda.min")
coefficient.ridge
predict.lasso <- predict(ridge.train, newx = as.matrix(test[,c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", 
                                 "te_cap_pct", "ol_cap_pct", "lb_cap_pct", 
                                 "db_cap_pct", "dl_cap_pct", "s_cap_pct", 
                                 "spec_cap_pct")]), s = "lambda.min")
pred_champ<-ifelse(predict.lasso>0.9,1,0)
confusionMatrix(as.factor(pred_champ), as.factor(test$is_champion))
```
```{r}
pred_24_lasso <- as.matrix(pred_24[, c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", "lb_cap_pct", "db_cap_pct","te_cap_pct","ol_cap_pct","dl_cap_pct","s_cap_pct","spec_cap_pct")])
pred<-predict(ridge.train,newx=pred_24_lasso, s = "lambda.min")
order(pred, decreasing = TRUE)
pred_24[order(pred, decreasing = TRUE),]
```
Elastic Net
```{r}
library(glmnet)

train_clean <- na.omit(train[, c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", 
                                 "te_cap_pct", "ol_cap_pct", "lb_cap_pct", 
                                 "db_cap_pct", "dl_cap_pct", "s_cap_pct", 
                                 "spec_cap_pct", "is_champion")])

x<-as.matrix(train_clean[,1:10])

y<-train_clean$is_champion

class_weights2 <- ifelse(train_clean$is_champion==1,
                        1/sum(train_clean$is_champion==1,na.rm=TRUE),
                        1/sum(train_clean$is_champion==0,na.rm=TRUE))
ridge.train.net = cv.glmnet(x, y, family = "binomial",alpha = 0.5,weights = class_weights2)
coefficient.ridge.net = coef(ridge.train.net, s = "lambda.min")
coefficient.ridge.net
predict.net <- predict(ridge.train.net, newx = as.matrix(test[,c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", 
                                 "te_cap_pct", "ol_cap_pct", "lb_cap_pct", 
                                 "db_cap_pct", "dl_cap_pct", "s_cap_pct", 
                                 "spec_cap_pct")]), s = "lambda.min")
pred_champ<-ifelse(predict.net>0.5,1,0)
confusionMatrix(as.factor(pred_champ), as.factor(test$is_champion))
```
```{r}
pred_24_net <- as.matrix(pred_24[, c("qb_cap_pct", "rb_cap_pct", "wr_cap_pct", "lb_cap_pct", "db_cap_pct","te_cap_pct","ol_cap_pct","dl_cap_pct","s_cap_pct","spec_cap_pct")])
pred<-predict(ridge.train.net,newx=pred_24_net, s = "lambda.min")
order(pred, decreasing = TRUE)
pred_24[order(pred, decreasing = TRUE),]
```


Random Forest
```{r}
library(randomForest)

rf_model <- randomForest(as.factor(is_champion) ~ qb_cap_pct + rb_cap_pct + wr_cap_pct + te_cap_pct + ol_cap_pct + lb_cap_pct + db_cap_pct + dl_cap_pct + s_cap_pct + spec_cap_pct ,
                         data = train,
                         classwt = c("0" = 1, "1" = 10),
                         na.action=na.exclude)  

pred_r<-predict(model_w,newdata=test,type="response")
pred_champ_r<-ifelse(pred_r>0.5,1,0)
confusionMatrix(as.factor(pred_champ_r), as.factor(test$is_champion))

```
```{r}
pred<-predict(rf_model,newdata=pred_24,type="response")
order(pred, decreasing = TRUE)
pred_24[order(pred, decreasing = TRUE),]
```

xgboost
```{r}
# Load the library
library(xgboost)

# Prepare data
xgb_train <- xgb.DMatrix(data = as.matrix(x_train), label = as.matrix(y_train))
xgb_test <- xgb.DMatrix(data = as.matrix(x_test), label = as.matrix(y_test))

# Watchlist to track training and test performance
watchlist <- list(train = xgb_train, test = xgb_test)

params <- list(booster = "gbtree", objective = "binary:logistic", eta=0.3, gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1, scale_pos_weight = 5)

xgbcv <- xgb.cv(params = params, data = xgb_train, nrounds = 11, nfold = 5, showsd = T, stratified = T, early_stop_round = 20, maximize = F)
min(xgbcv$evaluation_log$test_logloss_mean)
```

```{r}
xgb1 <- xgb.train (params = params, data = xgb_train, nrounds = 11, watchlist = watchlist, print_every_n = 10, early_stop_round = 10, maximize = F , eval_metric = "error")

predicted_probabilities <- predict(xgb1, xgb_test)
xgbpred <- ifelse (predicted_probabilities > 0.5,1,0)

table(Predicted = xgbpred, Actual = y_test$is_champion)

```

```{r}
# Get feature importance
importance <- xgb.importance(feature_names = colnames(x_train), model = xgb1)

# Print importance
print(importance)

# Plot feature importance
xgb.plot.importance(importance_matrix = importance)

```
```{r}
y_ischamp <- factor(y_train$is_champion, levels = c(0, 1), labels = c("No", "Yes"))
set.seed(1234)
# Train with random search
train_control <- trainControl(
  method = "cv", number = 5,       # 5-fold cross-validation
  verboseIter = TRUE,
  classProbs = TRUE,
  search = "random"                # Random search
)

best_train <- train(
  x = as.matrix(x_train),
  y = y_ischamp,
  method = "xgbTree",
  trControl = train_control,
  metric = "ROC",
  tuneLength = 10                  # Number of random combinations to try
)

# View the best parameters
best_train$bestTune

```

```{r}
bparams <- as.list(best_train$bestTune)
nrd <- bparams$nrounds
bparams$nrounds <- NULL  # Remove nrounds from the parameter list

# Add other parameters required for xgb.train
bparams$objective <- "binary:logistic"  # Specify the objective
bparams$scale_pos_weight <- sum(y_train$is_champion == 0) / sum(y_train$is_champion == 1)

final_mod <-xgb.train (params = bparams, data = xgb_train, nrounds = nrd, watchlist = watchlist, print_every_n = 10, early_stop_round = 10, maximize = F , eval_metric = "error")
```
```{r}
importance <- xgb.importance(feature_names = colnames(x_train), model = final_mod)

# Print importance
print(importance)

# Plot feature importance
xgb.plot.importance(importance_matrix = importance)
```
```{r}
# Predict probabilities for the test set
predicted_probabilities <- predict(final_mod, xgb_test)

# Display the first few predicted probabilities
head(predicted_probabilities)

# Set a threshold (e.g., 0.5)
threshold <- 0.7

# Convert probabilities to binary class predictions
predicted_labels <- ifelse(predicted_probabilities > threshold, 1, 0)

# Display the first few predicted labels
head(predicted_labels)
# Confusion matrix
table(Predicted = predicted_labels, Actual = y_test$is_champion)

library(Metrics)

# Calculate AUC
auc_value <- auc(y_test$is_champion, predicted_probabilities)
print(paste("AUC:", auc_value))
```

Predicting the 2024 NFL Champion
```{r}
xgb_24_test <- xgb.DMatrix(data = as.matrix(pred_24[,3:13]))
pred24 <- predict(final_mod, xgb_24_test)
champ_xg<-pred_24[order(pred24, decreasing = TRUE),]
pred_24[which(pred24>threshold),]
```

Current championship odds rankings 2024:
```{r}
champ_odds <- data.frame(
  team = c("DET","KC","BUF","PHI","BAL","GB","MIN","PIT","HOU","LAC","SEA","WAS","TB","DEN","ATL","ARI","LV","SF","MIA","IND","CIN","NO","CAR","DAL","CHI","CLV","TEN","JAX","NYJ","LA","NYG","NE"),
  rank = 1:32
)
champ_log$log_rank <- 1:32
champ_w$wlog_rank <- 1:32
champ_xg$xg_rank <- 1:32

dif_log<-merge(champ_log[,c(2,16)],champ_odds,by="team")
dif_wlog<-merge(champ_w[,c(2,16)],champ_odds,by="team")
dif_xg<-merge(champ_xg[,c(2,16)],champ_odds,by="team")

dif_log$diff_log <- dif_log$log_rank-dif_log$rank
dif_wlog$diff_wlog <- dif_wlog$wlog_rank-dif_wlog$rank
dif_xg$diff_xg <- dif_xg$xg_rank-dif_xg$rank

dif_log
dif_wlog
dif_xg

mod_champ<-merge(dif_log[,c(1,2,4)],dif_wlog[,c(1,2,4)],by="team")|>
  merge(x=_,dif_xg[c(1,2,4,3)], by ="team")

mod_champ[order(mod_champ$rank,decreasing=FALSE),c(1,8,2,4,6,3,5,7)]

mean_diffs <- data.frame(
  model = c("Logisitic","Weighted Logisitc","XGBoost"),
  mean_diff = c(mean(abs(mod_champ$log_rank-mod_champ$rank)),mean(abs(mod_champ$wlog_rank-mod_champ$rank)),mean(abs(mod_champ$xg_rank-mod_champ$rank)))
)

mean_diffs
```
```{r}
data.frame(
  team = c("KC","MIN","KC"),
  model = c("Logisitic","Weighted Logisitc","XGBoost")
)
```
